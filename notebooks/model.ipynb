{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woden/anaconda3/envs/ric_gis2_py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/woden/anaconda3/envs/ric_gis2_py39/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from p_drought_indices.functions.function_clns import load_config\n",
    "\n",
    "CONFIG_PATH= \"../config.yaml\"\n",
    "\n",
    "config_file = load_config(CONFIG_PATH=CONFIG_PATH)\n",
    "\n",
    "# Open the NetCDF file with xarray\n",
    "dataset = xr.open_dataset(os.path.join(config_file['NDVI']['ndvi_path'], 'smoothed_ndvi_1.nc'))\n",
    "\n",
    "time_end = \"2008-12-31\"\n",
    "time_start = \"2008-06-01\"\n",
    "\n",
    "dim=64\n",
    "ds = dataset.sel(time=slice(time_start,time_end)).isel(lat=slice(0,dim), lon=slice(0,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_directories = [config_file['SPI']['IMERG']['path'], config_file['SPI']['GPCC']['path'], config_file['SPI']['CHIRPS']['path'], config_file['SPI']['ERA5']['path'], config_file['SPI']['MSWEP']['path'] ]\n",
    "config_dir_precp = [config_file['PRECIP']['IMERG']['path'],config_file['PRECIP']['CHIRPS_05']['path'], config_file['PRECIP']['GPCC']['path'], config_file['PRECIP']['CHIRPS']['path'], config_file['PRECIP']['ERA5']['path'],  config_file['PRECIP']['TAMSTAT']['path'],config_file['PRECIP']['MSWEP']['path']]\n",
    "        \n",
    "prod = \"CHIRPS\"\n",
    "late = 60\n",
    "product_dir = [f for f in config_dir_precp if prod in f][0]\n",
    "list_files = [f for f in os.listdir(product_dir) if (f.endswith(\".nc\")) and (\"merged\" in f)]\n",
    "precp_ds = xr.open_dataset(os.path.join(product_dir, list_files[0]))\n",
    "variable = [var for var in precp_ds.data_vars if var!= \"spatial_ref\"][0]\n",
    "\n",
    "sub_precp= precp_ds.sel(time=slice(time_start,time_end)).isel(lat=slice(0,dim), lon=slice(0,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_drought_indices.functions.function_clns import prepare\n",
    "\n",
    "ds = prepare(ds)\n",
    "sub_precp = prepare(sub_precp)\n",
    "\n",
    "veg_repr = ds[\"ndvi\"].rio.reproject_match(sub_precp[variable]).rename({'x':'lon','y':'lat'})\n",
    "\n",
    "### converting null values to -99\n",
    "sub_veg = veg_repr.where(veg_repr.notnull(), -99)\n",
    "sub_precp = sub_precp.assign(null_precp = sub_precp[variable].where(sub_precp[variable].notnull(), -99))\n",
    "\n",
    "# Read the data as a numpy array\n",
    "target = sub_veg.transpose(\"lat\",\"lon\",\"time\").values\n",
    "data = sub_precp[\"null_precp\"].transpose(\"lat\",\"lon\",\"time\").values\n",
    "\n",
    "target = np.array(target)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = data.shape[-1]\n",
    "\n",
    "split = 0.8\n",
    "train_samples = int(round(split*n_samples, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_channel(data, n_samples):\n",
    "\n",
    "    # define the desired size of the time steps and number of channels \n",
    "    # ##output: (num_samples, num_frames, num_channels, height, width)\n",
    "    n_timesteps = n_samples\n",
    "    n_channels = 1\n",
    "\n",
    "    # determine the number of samples based on the desired number of time steps\n",
    "    n_samples = data.shape[-1] // n_timesteps\n",
    "\n",
    "    # reshape the input data into a 4D tensor\n",
    "    input_data = np.reshape(data, (data.shape[0], data.shape[1], n_timesteps, n_samples))\n",
    "\n",
    "    # add an extra dimension for the channels\n",
    "    input_data = np.reshape(input_data, (n_samples, n_timesteps,n_channels, input_data.shape[0], input_data.shape[1]))\n",
    "\n",
    "    # check the shape of the input data\n",
    "    print(input_data.shape) # should print (n_samples, n_timesteps, lat, lon, n_channels)\n",
    "    return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 214, 1, 64, 64)\n",
      "(1, 214, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "input_data = add_channel(data, n_samples)\n",
    "target_data = add_channel(target, n_samples)\n",
    "train_data = input_data[:,:train_samples,:,:]\n",
    "test_data =  input_data[:,train_samples:,:,:]\n",
    "train_label = target_data[:,:train_samples,:,:]\n",
    "test_label =  target_data[:,train_samples:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "    \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create a CustomDataset object using the reshaped input data\n",
    "train_dataset = CustomDataset(train_data, train_label)\n",
    "test_dataset = CustomDataset(test_data, test_label)\n",
    "\n",
    "# create a DataLoader object that uses the dataset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 171, 1, 64, 64]) torch.Size([1, 171, 1, 64, 64]) tensor(24.5388) tensor(-99.)\n",
      "torch.Size([1, 43, 1, 64, 64]) torch.Size([1, 43, 1, 64, 64]) tensor(51.9347) tensor(-99.)\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
    "    inputs = inputs.float()\n",
    "    targets = targets.float()\n",
    "    print(inputs.shape, targets.shape, inputs.max(), inputs.min())\n",
    "\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n",
    "    inputs = inputs.float()\n",
    "    targets = targets.float()\n",
    "    print(inputs.shape, targets.shape, inputs.max(), inputs.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvLSTMBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_features, kernel_size=3, padding=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.conv = self._make_layer(in_channels+num_features, num_features*4,\n",
    "                                       kernel_size, padding, stride)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, kernel_size, padding, stride):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels,\n",
    "                      kernel_size=kernel_size, padding=padding, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        :param inputs: (B, S, C, H, W)\n",
    "        :param hidden_state: (hx: (B, S, C, H, W), cx: (B, S, C, H, W))\n",
    "        :return:\n",
    "        '''\n",
    "        outputs = []\n",
    "        B, S, C, H, W = inputs.shape\n",
    "        hx = torch.zeros(B, self.num_features, H, W).to(inputs.device)\n",
    "        cx = torch.zeros(B, self.num_features, H, W).to(inputs.device)\n",
    "        for t in range(S):\n",
    "            combined = torch.cat([inputs[:, t], # (B, C, H, W)\n",
    "                                  hx], dim=1)\n",
    "            gates = self.conv(combined)\n",
    "            ingate, forgetgate, cellgate, outgate = torch.split(gates, self.num_features, dim=1)\n",
    "            ingate = torch.sigmoid(ingate)\n",
    "            forgetgate = torch.sigmoid(forgetgate)\n",
    "            outgate = torch.sigmoid(outgate)\n",
    "\n",
    "            cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "            hy = outgate * torch.tanh(cy)\n",
    "            outputs.append(hy)\n",
    "            hx = hy\n",
    "            cx = cy\n",
    "\n",
    "        return torch.stack(outputs).permute(1, 0, 2, 3, 4).contiguous() # (S, B, C, H, W) -> (B, S, C, H, W)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for idx, params in enumerate(config.encoder):\n",
    "            setattr(self, params[0]+'_'+str(idx), self._make_layer(*params))\n",
    "            self.layers.append(params[0]+'_'+str(idx))\n",
    "\n",
    "    def _make_layer(self, type, activation, in_ch, out_ch, kernel_size, padding, stride):\n",
    "        layers = []\n",
    "        if type == 'conv':\n",
    "            layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "            if activation == 'leaky': layers.append(nn.LeakyReLU(inplace=True))\n",
    "            elif activation == 'relu': layers.append(nn.ReLU(inplace=True))\n",
    "        elif type == 'convlstm':\n",
    "            layers.append(ConvLSTMBlock(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (B, S, C, H, W)\n",
    "        :return:\n",
    "        '''\n",
    "        outputs = [x]\n",
    "        for layer in self.layers:\n",
    "            if 'conv_' in layer:\n",
    "                B, S, C, H, W = x.shape\n",
    "                x = x.view(B*S, C, H, W)\n",
    "            x = getattr(self, layer)(x)\n",
    "            if 'conv_' in layer: x = x.view(B, S, x.shape[1], x.shape[2], x.shape[3])\n",
    "            if 'convlstm' in layer: outputs.append(x)\n",
    "        return outputs\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for idx, params in enumerate(config.decoder):\n",
    "            setattr(self, params[0]+'_'+str(idx), self._make_layer(*params))\n",
    "            self.layers.append(params[0]+'_'+str(idx))\n",
    "\n",
    "    def _make_layer(self, type, activation, in_ch, out_ch, kernel_size, padding, stride):\n",
    "        layers = []\n",
    "        if type == 'conv':\n",
    "            layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "            if activation == 'leaky': layers.append(nn.LeakyReLU(inplace=True))\n",
    "            elif activation == 'relu': layers.append(nn.ReLU(inplace=True))\n",
    "            elif activation == 'sigmoid': layers.append(nn.Sigmoid())\n",
    "        elif type == 'convlstm':\n",
    "            layers.append(ConvLSTMBlock(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride))\n",
    "        elif type == 'deconv':\n",
    "            layers.append(nn.ConvTranspose2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "            if activation == 'leaky': layers.append(nn.LeakyReLU(inplace=True))\n",
    "            elif activation == 'relu': layers.append(nn.ReLU(inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, encoder_outputs):\n",
    "        '''\n",
    "        :param x: (B, S, C, H, W)\n",
    "        :return:\n",
    "        '''\n",
    "        idx = len(encoder_outputs)-1\n",
    "        for layer in self.layers:\n",
    "            if 'conv_' in layer or 'deconv_' in layer:\n",
    "                x = encoder_outputs[idx]\n",
    "                B, S, C, H, W = x.shape\n",
    "                x = x.view(B*S, C, H, W)\n",
    "                x = getattr(self, layer)(x)\n",
    "                x = x.view(B, S, x.shape[1], x.shape[2], x.shape[3])\n",
    "            elif 'convlstm' in layer:\n",
    "                idx -= 1\n",
    "                x = torch.cat([encoder_outputs[idx], x], dim=2)\n",
    "                x = getattr(self, layer)(x)\n",
    "                encoder_outputs[idx] = x\n",
    "        return x\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, logger, epoch, model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    epoch_records = {'loss': []}\n",
    "    num_batchs = len(train_loader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        print(inputs.max())\n",
    "        inputs = inputs.float().to(config.device)\n",
    "        targets = targets.float().to(config.device)\n",
    "        outputs = model(inputs)\n",
    "        losses = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        epoch_records['loss'].append(losses.item())\n",
    "        if batch_idx and batch_idx % config.display == 0:\n",
    "            logger.info('EP:{:03d}\\tBI:{:05d}/{:05d}\\tLoss:{:.6f}({:.6f})'.format(epoch, batch_idx, num_batchs,\n",
    "                                                                                epoch_records['loss'][-1], np.mean(epoch_records['loss'])))\n",
    "    return epoch_records\n",
    "\n",
    "def valid(config, logger, epoch, model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_records = {'loss': []}\n",
    "    num_batchs = len(valid_loader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.float().to(config.device)\n",
    "            targets = targets.float().to(config.device)\n",
    "            outputs = model(inputs)\n",
    "            losses = criterion(outputs, targets)\n",
    "            epoch_records['loss'].append(losses.item())\n",
    "            if batch_idx and batch_idx % config.display == 0:\n",
    "                logger.info('[V] EP:{:03d}\\tBI:{:05d}/{:05d}\\tLoss:{:.6f}({:.6f})'.format(epoch, batch_idx, num_batchs,\n",
    "                                                                                    epoch_records['loss'][-1], np.mean(epoch_records['loss'])))\n",
    "    return epoch_records\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "def build_logging(config):\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "                        datefmt='%m-%d %H:%M',\n",
    "                        filename=os.path.join(config.log_dir, time.strftime(\"%Y%d%m_%H%M\") + '.log'),\n",
    "                        filemode='w')\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger('').addHandler(console)\n",
    "    return logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n",
      "tensor(24.5388)\n"
     ]
    }
   ],
   "source": [
    "from p_drought_indices.configs.config_3x3_16_3x3_32_3x3_64 import config\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name = '3x3_16_3x3_32_3x3_64'\n",
    "\n",
    "logger = build_logging(config)\n",
    "model = ConvLSTM(config).to(config.device)\n",
    "#criterion = CrossEntropyLoss().to(config.device)\n",
    "#criterion = torch.nn.MSELoss().to(config.device)\n",
    "criterion = MSELoss().to(config.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_records, valid_records, test_records = [], [], []\n",
    "for epoch in range(config.epochs):\n",
    "    epoch_records = train(config, logger, epoch, model, train_dataloader, criterion, optimizer)\n",
    "    train_records.append(np.mean(epoch_records['loss']))\n",
    "    epoch_records = valid(config, logger, epoch, model, test_dataloader, criterion)\n",
    "    valid_records.append(np.mean(epoch_records['loss']))\n",
    "    plt.plot(range(epoch + 1), train_records, label='train')\n",
    "    plt.plot(range(epoch + 1), valid_records, label='valid')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(config.output_dir, '{}.png'.format(name)))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
