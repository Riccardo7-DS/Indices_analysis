{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_drought_indices.functions.function_clns import load_config, cut_file, subsetting_pipeline\n",
    "from p_drought_indices.functions.ndvi_functions import downsample, clean_ndvi, compute_ndvi, clean_outliers\n",
    "from p_drought_indices.vegetation.cloudmask_cleaning import extract_apply_cloudmask, plot_cloud_correction, compute_difference, compute_correlation\n",
    "import xarray as xr \n",
    "import pandas as pd\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "import shutil\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "#import datetime as datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "from p_drought_indices.vegetation.NDVI_indices import compute_svi, compute_vci\n",
    "from p_drought_indices.analysis.metrics_table import MetricTable\n",
    "\n",
    "CONFIG_PATH = r\"../config.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and smoothing NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = {\"lat\": -1, \"lon\": -1, \"time\": 12}\n",
    "## Uncomment for AVHRR data\n",
    "#path = r'D:\\shareVM\\MSG\\AVHRR\\processed\\*.nc'\n",
    "#data = xr.open_mfdataset(path, chunks=chunks)\n",
    "#data = data.rename({'longitude':'lon', 'latitude':'lat'})\n",
    "\n",
    "ndvi_dir = r'D:\\shareVM\\MSG\\msg_data\\batch_2\\processed'\n",
    "list_files = [os.path.join(ndvi_dir,file) for file in os.listdir(ndvi_dir) if re.match('HRSEVIRI_200\\d+.*', file)]\n",
    "xr_df = xr.open_mfdataset(list_files, chunks=chunks)\n",
    "\n",
    "xr_df = clean_outliers(xr_df)\n",
    "\n",
    "CONFIG_PATH = r\"../config.yaml\"\n",
    "\n",
    "config = load_config(CONFIG_PATH)\n",
    "shapefile_path = config['SHAPE']['africa']\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "countries = ['Ethiopia','Kenya','Somalia']\n",
    "\n",
    "subset = gdf[gdf.ADM0_NAME.isin(countries)]\n",
    "#ds_avh = cut_file(data, subset)\n",
    "\n",
    "base_dir = r'D:\\shareVM\\MSG\\cloudmask\\processed_clouds\\batch_2\\nc_files\\new\\ndvi_mask.nc'\n",
    "cl_df = xr.open_mfdataset(base_dir, chunks=chunks)\n",
    "cl_df = cl_df.sel(time=slice(cl_df['time'].min(), '2009-12-31'))\n",
    "\n",
    "ds = cut_file(xr_df, subset)\n",
    "ds_cl = cut_file(cl_df, subset)\n",
    "mask_clouds, res_xr = extract_apply_cloudmask(ds, ds_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_drought_indices.vegetation.cloudmask_cleaning import apply_whittaker\n",
    "\n",
    "result = apply_whittaker(mask_clouds['ndvi'])\n",
    "result.to_netcdf(r'D:\\shareVM\\MSG\\msg_data\\processed\\smoothed_ndvi.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_df = xr.open_dataset(r'D:\\shareVM\\MSG\\msg_data\\processed\\smoothed_ndvi.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " c:\\users\\riccardo\\desktop\\phd_docs\\drought_prediction\\project\\indices_analysis\\p_drought_indices\\vegetation\\NDVI_indices.py:59: RuntimeWarning:invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "vci = compute_vci(veg_df['ndvi'])\n",
    "#res = compute_svi(res_xr)\n",
    "vci.to_netcdf(r'D:\\shareVM\\MSG\\msg_data\\processed\\vci_1D.nc')\n",
    "#res.to_netcdf(r'D:\\shareVM\\MSG\\msg_data\\processed\\svi_1D.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop to apply tablemetric for vci to each product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "product_directory =  r\"D:\\shareVM\\MSG\\msg_data\\processed\"\n",
    "var = 'vci'\n",
    "table_metrics = pd.DataFrame()\n",
    "for country in ['Ethiopia','Somalia','Kenya']:\n",
    "    for product_dir in [config['SPI']['IMERG']['path'], config['SPI']['GPCC']['path'], config['SPI']['CHIRPS']['path'], config['SPI']['ERA5']['path']]:\n",
    "        for late in [30, 60, 90, 180]:\n",
    "            var_target = f\"spi_gamma_{late}\"\n",
    "            spi = MetricTable(product_directory, product_dir, var, var_target, CONFIG_PATH, countries=[country])\n",
    "            spi.compute_metrics_soil(freq=\"daily\")\n",
    "            table_df = spi.df_cover\n",
    "            table_metrics = pd.concat([table_metrics, table_df],ignore_index=True)\n",
    "\n",
    "table_metrics.to_csv(r'../data/spi_vci/spi_vci_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_data(data, metric, precp_idx, country, product):\n",
    "    y = data[metric].loc[(data['precp_idx'] == precp_idx) & (data['country'] == country)\\\n",
    "        & (data['product'] == product)]\n",
    "\n",
    "    #y.dropna().plot(kind='hist', bins=30, kde=True)\n",
    "    sns.displot(y.dropna(), kde=True)\n",
    "    plt.title(f\"metric {metric} for {precp_idx} {product} in {country}\")\n",
    "    plt.show()\n",
    "\n",
    "def group_plot(data, country, product):\n",
    "    grouped = data.loc[(data['country'] == country)\\\n",
    "                & (data['product'] == product)]\n",
    "    grouped = grouped.groupby(['precp_idx'])\n",
    "    fig, ax = plt.subplots()\n",
    "    grouped.plot(kind='hist', y='far', ax=ax, legend=True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_data_spi(data, metric, country, product):\n",
    "    spi_list = table_metrics['precp_idx'].unique()\n",
    "    fig, ax = plt.subplots(1,4)\n",
    "\n",
    "    for i, spi in enumerate(spi_list):\n",
    "        y = data[metric].loc[(data['country'] == country)\\\n",
    "            & (data['product'] == product)]\n",
    "        y= y.dropna()\n",
    "\n",
    "        sns.displot(y, kde=True)\n",
    "    #plt.title(f\"metric {metric} for {product} in {country}\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'../data/spi_vci/spi_vci_daily.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric ='pod' \n",
    "precp_idx= 'spi_gamma_180'\n",
    "country='Ethiopia' \n",
    "product=\"IMERG\"\n",
    "\n",
    "for metric in ['pod','far','accuracy']:\n",
    "    print(f\"Printing {metric}\")\n",
    "    for country in ['Ethiopia','Kenya','Somalia']:\n",
    "        y = plot_data(table_metrics, metric, precp_idx, country, product)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('gis2_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1acf0cf36a713a20e6f2f6b404d47f8424c3d1e89d00c3598e855a17bfb20dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
