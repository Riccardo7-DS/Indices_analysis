{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_drought_indices.analysis.DeepLearning.pipeline_gwnet import data_preparation \n",
    "from p_drought_indices.analysis.DeepLearning.pipeline_convlstm import training_lstm\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from p_drought_indices.functions.function_clns import load_config, prepare, CNN_split, interpolate_prepare\n",
    "import numpy as np\n",
    "from p_drought_indices.analysis.DeepLearning.dataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "CONFIG_PATH = \"../config.yaml\"\n",
    "sub_precp, ds = data_preparation(CONFIG_PATH)\n",
    "sub_precp = sub_precp.to_dataset()\n",
    "data, target = interpolate_prepare(sub_precp, ds)\n",
    "train_split = 0.8\n",
    "training_lstm(CONFIG_PATH, data, target, train_split = train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_CHECK(data_array:xr.DataArray):\n",
    "    # Check shape and size\n",
    "    print(\"Shape:\", data_array.shape)\n",
    "    print(\"Size:\", data_array.size)\n",
    "    \n",
    "    # Check coordinates and dimensions\n",
    "    print(\"Dimensions:\", data_array.dims)\n",
    "    print(\"Coordinates:\", data_array.coords)\n",
    "    \n",
    "    # Check data type and values\n",
    "    print(\"Data Type:\", data_array.dtype)\n",
    "    print(\"Data Values:\", data_array.values)\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"Missing Values:\", data_array.isnull().any())\n",
    "    \n",
    "    # Check attributes\n",
    "    print(\"Attributes:\", data_array.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Riccardo\\anaconda3\\envs\\gis2_py39\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from p_drought_indices.analysis.DeepLearning.pipeline_gwnet import data_preparation, get_dataloader, main\n",
    "from p_drought_indices.analysis.DeepLearning.pipeline_convlstm import training_lstm\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from p_drought_indices.functions.function_clns import load_config, prepare, CNN_split, interpolate_prepare, subsetting_pipeline, get_lat_lon_window\n",
    "import numpy as np\n",
    "from p_drought_indices.analysis.DeepLearning.dataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "CONFIG_PATH = \"../config.yaml\"\n",
    "config = load_config(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_precp, ds =  data_preparation(CONFIG_PATH, ndvi_dataset=\"smoothed_ndvi_1_old.nc\")\n",
    "x_df = sub_precp.to_dataframe()\n",
    "x_df_1 = x_df.swaplevel(1,2)\n",
    "for col in [\"spatial_ref\",\"crs\"]:\n",
    "    if col in x_df_1:\n",
    "        x_df_1.drop(columns={col}, inplace=True)\n",
    "x_df_2 = x_df_1.dropna(subset={\"tp\"})\n",
    "x_df_3 = x_df_2.sort_values([\"lat\", \"lon\",\"time\"],ascending=False)\n",
    "data_x_unstack = x_df_3.unstack([\"lat\",\"lon\"])\n",
    "#x_unstack = data_x_unstack.to_numpy()\n",
    "num_samples, num_nodes = data_x_unstack.shape\n",
    "x_unstack = np.expand_dims(data_x_unstack, axis=-1)\n",
    "print(\"The features have dimensions:\", x_unstack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = ds.to_dataframe()\n",
    "for col in [\"spatial_ref\",\"crs\"]:\n",
    "    if col in y_df:\n",
    "        y_df.drop(columns={col}, inplace=True)\n",
    "y_df = y_df.dropna(subset={\"ndvi\"})\n",
    "y_df = y_df.sort_values([\"lat\", \"lon\",\"time\"],ascending=False)\n",
    "y_df = y_df.reset_index().set_index([\"time\",\"lon\",\"lat\"])\n",
    "y_df = y_df[y_df.index.isin(x_df_3.index)]\n",
    "data_y_unstack = y_df.unstack([\"lat\",\"lon\"])\n",
    "y_unstack = data_y_unstack.to_numpy()\n",
    "y_unstack = np.expand_dims(y_unstack, axis=-1)\n",
    "print(\"The instance have dimensions:\", y_unstack.shape)\n",
    "\n",
    "### changes with features\n",
    "st_df = x_df_3.reset_index()[[\"lon\",\"lat\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x_df, x_df_1, x_df_2, x_df_3, data_x_unstack]:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_drought_indices.analysis.DeepLearning.pipeline_gwnet import generate_adj_dist\n",
    "adj_dist = generate_adj_dist(st_df)\n",
    "seq_length_x = seq_length_y = 12\n",
    "y_start = 1\n",
    "x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n",
    "\n",
    "with open(os.path.join(config[\"DEFAULT\"][\"data\"], \"graph_net/big_adj_dist.pkl\"), 'wb') as f:\n",
    "        pickle.dump(adj_dist, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub_precp, n_ds =  data_preparation(CONFIG_PATH, ndvi_dataset=\"smoothed_ndvi_1.nc\")\n",
    "n_x_df = n_sub_precp.to_dataframe()\n",
    "n_x_df_1 = n_x_df.swaplevel(1,2)\n",
    "n_x_df_2 = n_x_df_1.dropna(subset={\"tp\"}).drop(columns={\"spatial_ref\",\"crs\"})\n",
    "n_x_df_3 = n_x_df_2.sort_values([\"lat\", \"lon\",\"time\"],ascending=False)\n",
    "n_data_x_unstack = n_x_df_3.unstack([\"lat\",\"lon\"])\n",
    "#x_unstack = data_x_unstack.to_numpy()\n",
    "n_num_samples, n_num_nodes = n_data_x_unstack.shape\n",
    "n_x_unstack = np.expand_dims(n_data_x_unstack, axis=-1)\n",
    "print(\"The features have dimensions:\", n_x_unstack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [n_x_df, n_x_df_1, n_x_df_2, n_x_df_3, n_data_x_unstack]:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y_df = n_ds.to_dataframe()\n",
    "n_y_df = n_y_df.dropna(subset={\"ndvi\"}).drop(columns={\"spatial_ref\",\"crs\"})\n",
    "n_y_df = n_y_df.sort_values([\"lat\", \"lon\",\"time\"],ascending=False)\n",
    "n_y_df = n_y_df.reset_index().set_index([\"time\",\"lon\",\"lat\"])\n",
    "n_y_df = n_y_df[n_y_df.index.isin(n_x_df_3.index)]\n",
    "n_data_y_unstack = n_y_df.unstack([\"lat\",\"lon\"])\n",
    "n_y_unstack = n_data_y_unstack.to_numpy()\n",
    "n_y_unstack = np.expand_dims(n_y_unstack, axis=-1)\n",
    "print(\"The instance have dimensions:\", n_y_unstack.shape)\n",
    "\n",
    "### changes with features\n",
    "n_st_df = n_x_df_3.reset_index()[[\"lon\",\"lat\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_drought_indices.analysis.DeepLearning.pipeline_gwnet import generate_adj_dist\n",
    "adj_dist = generate_adj_dist(n_st_df)\n",
    "with open(os.path.join(config[\"DEFAULT\"][\"data\"], \"graph_net/n_adj_dist.pkl\"), 'wb') as f:\n",
    "        pickle.dump(adj_dist, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_drought_indices.analysis.DeepLearning.pipeline_gwnet import load_dataset, MetricsRecorder\n",
    "\n",
    "output_dir = os.path.join(config[\"DEFAULT\"][\"data\"],  \"graph_net\")\n",
    "seq_length_x = seq_length_y = 12\n",
    "y_start = 1\n",
    "x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n",
    "\n",
    "# Predict the next one hour\n",
    "y_offsets = np.sort(np.arange(y_start, (seq_length_y + 1), 1))\n",
    "x, y = [], []\n",
    "min_t = abs(min(x_offsets))\n",
    "max_t = abs(num_samples - abs(max(y_offsets)))  # Exclusive\n",
    "\n",
    "for t in range(min_t, max_t):  # t is the index of the last observation.\n",
    "    x.append(x_unstack[t + x_offsets, ...])\n",
    "    y.append(y_unstack[t + y_offsets, ...])\n",
    "x = np.stack(x, axis=0)\n",
    "y = np.stack(y, axis=0)\n",
    "print(\"x shape: \", x.shape, \", y shape: \", y.shape)\n",
    "num_test = round(num_samples * 0.2)\n",
    "num_train = round(num_samples * 0.7)\n",
    "num_val = num_samples - num_test - num_train\n",
    "x_train, y_train = x[:num_train], y[:num_train]\n",
    "x_val, y_val = (\n",
    "    x[num_train: num_train + num_val],\n",
    "    y[num_train: num_train + num_val],\n",
    ")\n",
    "x_test, y_test = x[-num_test:], y[-num_test:]\n",
    "for cat in [\"train\", \"val\", \"test\"]:\n",
    "    _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
    "    print(cat, \"x: \", _x.shape, \"y:\", _y.shape)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(output_dir, f\"{cat}.npz\"),\n",
    "        x=_x,\n",
    "        y=_y,\n",
    "        x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
    "        y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
    "    )\n",
    "batch_size = config[\"GWNET\"][\"batch_size\"]\n",
    "dataloader = load_dataset(output_dir, batch_size, batch_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import time\n",
    "from p_drought_indices.analysis.DeepLearning.pipeline_gwnet import save_figures, trainer, load_adj\n",
    "device = \"cpu\" #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seq_length=12\n",
    "nhid=32\n",
    "in_dim =1\n",
    "adjtype = \"doubletransition\"\n",
    "learning_rate=0.001\n",
    "dropout=0.3\n",
    "weight_decay=0.0001\n",
    "gcn_bool = \"store_true\"\n",
    "addaptadj = \"store_true\"\n",
    "print_every = 50\n",
    "epochs = 50\n",
    "\n",
    "adj_path = os.path.join(config[\"DEFAULT\"][\"data\"], \"graph_net/big_adj_dist.pkl\")\n",
    "adj_mx = load_adj(adj_path,  adjtype)\n",
    "scaler = dataloader['scaler']\n",
    "supports = [torch.tensor(i).to(device) for i in adj_mx]\n",
    "metrics_recorder = MetricsRecorder()\n",
    "adjinit = supports[0]\n",
    "engine = trainer(scaler, in_dim, seq_length, num_nodes, nhid, dropout,\n",
    "                     learning_rate, weight_decay, device, supports, gcn_bool, addaptadj,\n",
    "                     adjinit)\n",
    "print(\"start training...\",flush=True)\n",
    "his_loss =[]\n",
    "val_time = []\n",
    "train_time = []\n",
    "for i in range(1,epochs+1):\n",
    "    train_loss = []\n",
    "    train_mape = []\n",
    "    train_rmse = []\n",
    "    t1 = time.time()\n",
    "    dataloader['train_loader'].shuffle()\n",
    "    for iter, (x, y) in enumerate(dataloader['train_loader'].get_iterator()):\n",
    "        trainx = torch.Tensor(x).to(device)\n",
    "        trainx= trainx.transpose(1, 3)\n",
    "        trainy = torch.Tensor(y).to(device)\n",
    "        trainy = trainy.transpose(1, 3)\n",
    "        metrics = engine.train(trainx, trainy[:,0,:,:])\n",
    "        train_loss.append(metrics[0])\n",
    "        train_mape.append(metrics[1])\n",
    "        train_rmse.append(metrics[2])\n",
    "        if iter % print_every == 0 :\n",
    "            log = 'Iter: {:03d}, Train Loss: {:.4f}, Train MAPE: {:.4f}, Train RMSE: {:.4f}'\n",
    "            print(log.format(iter, train_loss[-1], train_mape[-1], train_rmse[-1]),flush=True)\n",
    "    t2 = time.time()\n",
    "    train_time.append(t2-t1)\n",
    "    #validation\n",
    "    valid_loss = []\n",
    "    valid_mape = []\n",
    "    valid_rmse = []\n",
    "    s1 = time.time()\n",
    "    for iter, (x, y) in enumerate(dataloader['val_loader'].get_iterator()):\n",
    "        testx = torch.Tensor(x).to(device)\n",
    "        testx = testx.transpose(1, 3)\n",
    "        testy = torch.Tensor(y).to(device)\n",
    "        testy = testy.transpose(1, 3)\n",
    "        metrics = engine.eval(testx, testy[:,0,:,:])\n",
    "        valid_loss.append(metrics[0])\n",
    "        valid_mape.append(metrics[1])\n",
    "        valid_rmse.append(metrics[2])\n",
    "    \n",
    "    s2 = time.time()\n",
    "    log = 'Epoch: {:03d}, Inference Time: {:.4f} secs'\n",
    "    print(log.format(i,(s2-s1)))\n",
    "    val_time.append(s2-s1)\n",
    "    mtrain_loss = np.mean(train_loss)\n",
    "    mtrain_mape = np.mean(train_mape)\n",
    "    mtrain_rmse = np.mean(train_rmse)\n",
    "    metrics_recorder.add_train_metrics(mtrain_mape, mtrain_rmse, mtrain_loss)\n",
    "    mvalid_loss = np.mean(valid_loss)\n",
    "    mvalid_mape = np.mean(valid_mape)\n",
    "    mvalid_rmse = np.mean(valid_rmse)\n",
    "    his_loss.append(mvalid_loss)\n",
    "    metrics_recorder.add_val_metrics(mvalid_mape, mvalid_rmse, mvalid_loss)\n",
    "    save_figures(config=config, epoch=i, train_loss=metrics_recorder.train_loss, \n",
    "                train_mape=metrics_recorder.train_mape, train_rmse=metrics_recorder.train_rmse, \n",
    "                test_loss=metrics_recorder.val_loss, test_rmse=metrics_recorder.val_loss, \n",
    "                test_mape=metrics_recorder.val_mape)\n",
    "    log = 'Epoch: {:03d}, Train Loss: {:.4f}, Train MAPE: {:.4f}, Train RMSE: {:.4f}, Valid Loss: {:.4f}, Valid MAPE: {:.4f}, Valid RMSE: {:.4f}, Training Time: {:.4f}/epoch'\n",
    "    print(log.format(i, mtrain_loss, mtrain_mape, mtrain_rmse, mvalid_loss, mvalid_mape, mvalid_rmse, (t2 - t1)),flush=True)\n",
    "    #torch.save(engine.model.state_dict(), args.save+\"_epoch_\"+str(i)+\"_\"+str(round(mvalid_loss,2))+\".pth\")\n",
    "print(\"Average Training Time: {:.4f} secs/epoch\".format(np.mean(train_time)))\n",
    "print(\"Average Inference Time: {:.4f} secs\".format(np.mean(val_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
