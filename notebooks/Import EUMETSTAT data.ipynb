{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9875cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eumdac\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import shutil\n",
    "from shapely.geometry import Polygon, mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from configparser import ConfigParser\n",
    "from mpop import CONFIG_PATH\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(CONFIG_PATH):\n",
    "    with open(CONFIG_PATH) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        return config\n",
    "\n",
    "import os\n",
    "\n",
    "CONFIG_PATH = r\"./config.yaml\"\n",
    "\n",
    "\n",
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "# Insert your personal key and secret into the single quotes\n",
    "consumer_key = config['DEFAULT']['key']\n",
    "consumer_secret = config['DEFAULT']['secret']\n",
    "\n",
    "credentials = (consumer_key, consumer_secret)\n",
    "\n",
    "token = eumdac.AccessToken(credentials)\n",
    "\n",
    "print(f\"This token '{token}' expires {token.expiration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = eumdac.DataStore(token)\n",
    "selected_collection = datastore.get_collection('EO:EUM:DAT:METOP:SOMO25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML \n",
    "# Display the details for the selected collection\n",
    "display(HTML('<b>'+selected_collection.title+'</b>'))\n",
    "display(HTML('<b>ID:</b> '+str(selected_collection)))\n",
    "display(HTML('<b>Abstract:</b> '+selected_collection.abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionID ='EO:EUM:DAT:MSG:HRSEVIRI'\n",
    "\n",
    "datastore = eumdac.DataStore(token)\n",
    "datastore.collections\n",
    "\n",
    "selected_collection = datastore.get_collection(collectionID)\n",
    "bbox =[32.9, 3.2, 48, 15]\n",
    "#products = selected_collection.search(bbox=bbox) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac989bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add vertices for polygon, wrapping back to the start point.\n",
    "geometry = [[15,32.8],[2.9,32.8],[2.9,48],[48,15], [15,32.8]]\n",
    "\n",
    "download_dir = r'C:\\Users\\Riccardo\\Desktop\\PhD docs\\Drought prediction\\dataset\\EUMETSAT\\MSG'\n",
    "\n",
    "start_date = '2009-01-01 11:45:00'\n",
    "end_date= '2020-01-01 12:20:00'\n",
    "\n",
    "start_dt = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "end_dt = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S')\n",
    "delta = timedelta(days=1)\n",
    "time_window = timedelta(minutes=30)\n",
    "\n",
    "while start_dt <= end_dt:  \n",
    "    limit_dt = start_dt + time_window\n",
    "    # Retrieve datasets that match our filter\n",
    "    product = selected_collection.search(\n",
    "        geo='POLYGON(({}))'.format(','.join([\"{} {}\".format(*coord) for coord in geometry])),\n",
    "        #bbox=bbox,\n",
    "        dtstart=start_dt, \n",
    "        dtend=limit_dt).first()\n",
    "        \n",
    "    selected_product = datastore.get_product(product_id=str(product), collection_id=collectionID)\n",
    "    \n",
    "    try:\n",
    "        with selected_product.open() as fsrc, open(os.path.join(download_dir, fsrc.name), mode='wb') as fdst:\n",
    "            #print(f'Downloading {fsrc.name}')\n",
    "            shutil.copyfileobj(fsrc, fdst)\n",
    "            print(f'Download of product {fsrc.name} finished.')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('http error {} on day'.format(e), datetime.strftime(start_dt, format='%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    start_dt += delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe52ca",
   "metadata": {},
   "source": [
    "2011-03-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67158859",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Riccardo\\Desktop\\PhD docs\\Drought prediction\\ETH_adm\\gadm40_ETH_0.shp'\n",
    "eth_poly = gpd.read_file(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe98db8",
   "metadata": {},
   "source": [
    "### Processing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from satpy import DataQuery\n",
    "from pyresample.geometry import SwathDefinition\n",
    "from satpy import Scene\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from satpy.dataset import combine_metadata\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from satpy import Scene\n",
    "\n",
    "base_dir = r'D:\\MSG\\MSG_nat\\batch_2'\n",
    "file = r'MSG2-SEVI-MSG15-0100-NA-20110311121242.259000000Z-NA.nat'\n",
    "scn =Scene(filenames = {reader:[os.path.join(base_dir,file)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epct import api\n",
    "\n",
    "#fine the configuration of the functional chain to apply:\n",
    "chain_config = {\n",
    "       'name': 'sample_chain',\n",
    "       'product': 'HRSEVIRI',\n",
    "       'format': 'netcdf4',\n",
    "       'projection': 'geographic',\n",
    "   }\n",
    "\n",
    "base_dir = r'D:\\MSG\\MSG_nat\\batch_2'\n",
    "\n",
    "files = [f for f in os.listdir(base_dir) if f.endswith('.nat')]\n",
    "\n",
    "with open(r'C:\\Users\\Riccardo\\Desktop\\PhD_docs\\Drought_prediction\\ETH_adm.zip', 'rb') as f:\n",
    "     shapefile_stream = f.read()\n",
    "\n",
    "target_dir = r'D:\\MSG\\msg_data\\batch_2'\n",
    "#n the chain and return the result as an `xarray` object\n",
    "output_xarray_dataset = api.run_chain_to_xarray(\n",
    "   product_paths=[r'D:\\\\MSG\\MSG_nat\\batch_2\\MSG2-SEVI-MSG15-0100-NA-20110311121242.259000000Z-NA.nat'],\n",
    "   chain_config=chain_config,\n",
    "   target_dir=target_dir,\n",
    "   shapefile_stream=shapefile_stream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b4a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon, lat = scn[0.8].attrs['area'].get_lonlats()\n",
    "swath_def = SwathDefinition(lons=lon, lats=lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c38d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndvi(scn):\n",
    "    #lon, lat = scn[0.8].attrs['area'].get_lonlats()\n",
    "    ndvi = (scn[0.8] - scn[0.6]) / (scn[0.8] + scn[0.6])\n",
    "    ndvi.attrs = combine_metadata(scn[0.8], scn[0.6])\n",
    "    scn['ndvi'] = ndvi\n",
    "    return scn\n",
    "\n",
    "def from_nat_netcdf(file, reader = \"seviri_l1b_native\"):\n",
    "    scn =Scene(filenames = {reader:[file]})\n",
    "    #dataset_names = scn.all_dataset_names()\n",
    "    my_channel_id = DataQuery(name=['VIS006'], calibration='reflectance')\n",
    "    my_channel_id_2 = DataQuery(name=['VIS008'], calibration='reflectance')\n",
    "    scn.load([my_channel_id, my_channel_id_2])\n",
    "    scn_ndvi = compute_ndvi(scn)\n",
    "    return scn_ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c39a18",
   "metadata": {},
   "source": [
    "### Cut Ethiopia and convert to xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420fa427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "path = r'C:\\Users\\Riccardo\\Desktop\\PhD_docs\\Drought_prediction\\ETH_adm\\gadm40_ETH_0.shp'\n",
    "eth_poly = gpd.read_file(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd12c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epct import api\n",
    "\n",
    "# define the configuration of the functional chain to apply:\n",
    "chain_config = {\n",
    "       'name': 'sample_chain',\n",
    "       'product': 'HRSEVIRI',\n",
    "       'format': 'netcdf4',\n",
    "       'projection': 'geographic'}\n",
    "\n",
    "#ecify the input product paths and load the shapefile\n",
    "input_products = [\n",
    "    r'D:\\MSG\\MSG_nat\\batch_2\\msg2_sevi.nat',\n",
    "    ]\n",
    "\n",
    "with open(r'C:\\Users\\Riccardo\\Downloads\\gadm40_ETH_shp.zip', 'rb') as f:\n",
    "    shapefile_stream = f.read()\n",
    "\n",
    "\n",
    "#n the chain and return the result as an `xarray` object\n",
    "output_xarray_dataset = api.run_chain_to_xarray(\n",
    "   product_paths=input_products,\n",
    "   chain_config=chain_config,\n",
    "   target_dir=r'D:\\MSG\\msg_data\\batch_2',\n",
    "   shapefile_stream=shapefile_stream\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2368dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(base_dir,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ad624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from epct import api\n",
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "chain_config = {\"filter\": \"hrseviri_natural_color\",\n",
    "        \"name\": \"Natural color disc\",\n",
    "        \"id\": \"natural_color_disc\",\n",
    "        'product': 'HRSEVIRI',\n",
    "        'format': 'netcdf4',\n",
    "        'projection': 'geographic'\n",
    "    }\n",
    "\n",
    "#input_products = [\n",
    "#     r'D:\\MSG\\msg_data\\MSG2-SEVI-MSG15-0100-NA-20090108121240.961000000Z-NA.nat'\n",
    "# ]\n",
    "\n",
    "#files = glob('D:\\MSG\\msg_data\\*.nat')\n",
    "base_dir = r'D:\\MSG\\MSG_nat\\batch_1'\n",
    "files = [f for f in os.listdir(base_dir) if f.endswith('.nat')]\n",
    "\n",
    "with open(r'C:\\Users\\Riccardo\\Desktop\\PhD_docs\\Drought_prediction\\gadm40_ETH_shp.zip', 'rb') as f:\n",
    "     shapefile_stream = f.read()\n",
    "\n",
    "for file in files:\n",
    "    # run the chain and return the result as an `xarray` object\n",
    "    output_xarray_dataset = api.run_chain_to_xarray(\n",
    "       product_paths=[os.path.join(base_dir,file)],\n",
    "       chain_config=chain_config,\n",
    "       target_dir=r'D:\\MSG\\msg_data\\batch_2',\n",
    "       shapefile_stream=shapefile_stream\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df0b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "def add_time(xr_df):\n",
    "    my_date_string = xr_df.attrs['date_time'] \n",
    "    date_xr = datetime.strptime(my_date_string, '%Y%m%d/%H:%M')\n",
    "    date_xr = pd.to_datetime(date_xr)\n",
    "    xr_df = xr_df.assign_coords(time=date_xr)\n",
    "    xr_df = xr_df.expand_dims(dim=\"time\")\n",
    "    return xr_df\n",
    "\n",
    "def compute_radiance(xr_df):\n",
    "    satellite = xr_df.attrs['EPCT_product_name'][:4]\n",
    "    if satellite == 'MSG2':\n",
    "        xr_df['channel_1'] = xr_df['channel_1']/65.2065\n",
    "        xr_df['channel_2'] = xr_df['channel_2']/73.0127\n",
    "        \n",
    "    elif satellite == 'MSG1':\n",
    "        xr_df['channel_1'] = xr_df['channel_1']/65.2296 \n",
    "        xr_df['channel_2'] = xr_df['channel_2']/73.1869\n",
    "    \n",
    "    else:\n",
    "        print('This product doesn\\'t contain MSG1 or MSG2 Seviri')\n",
    "    \n",
    "    return xr_df\n",
    "        \n",
    "\n",
    "base_dir = r'D:\\MSG\\msg_data\\netcdf_data'\n",
    "files = [f for f in os.listdir(base_dir) if f.endswith('.nc')]\n",
    "\n",
    "for file in files:\n",
    "    with xr.open_dataset(os.path.join(base_dir, file)) as ds:\n",
    "        data = ds.load()\n",
    "        xr_df = add_time(data)\n",
    "        xr_df = compute_radiance(xr_df)\n",
    "        xr_df = xr_df.drop('channel_3')\n",
    "        xr_df = xr_df.assign(ndvi=(xr_df['channel_2'] - xr_df['channel_1']) / (xr_df['channel_2'] + xr_df['channel_1']))\n",
    "        #xr_df['channel_2'].plot()\n",
    "        xr_df.to_netcdf(os.path.join(base_dir,'processed', file)) \n",
    "        xr_df.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796818da",
   "metadata": {},
   "source": [
    "### Plot the average NDVI per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57606325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "base_dir = r'D:\\MSG\\msg_data\\netcdf_data\\processed'\n",
    "file = 'HRSEVIRI_20090101T121200Z_20090101T121200Z_epct_c0b84031_FP.nc'\n",
    "xr_df = xr.open_dataset(os.path.join(base_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_df['channel_1'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_df['channel_2'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997a98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xr_df['ndvi'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837bff2",
   "metadata": {},
   "source": [
    "### Cloudmask dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857b18d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "base_dir = r'D:\\MSG\\cloudmask\\processed_clouds'\n",
    "file = 'MSGCLMK_20100115T121500Z_20100115T121500Z_epct_82eea5af_P.nc'\n",
    "xr_df = xr.open_dataset(os.path.join(base_dir, file))\n",
    "xr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60737e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_df['cloud_mask'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def downsample(ds):\n",
    "    monthly = ds.resample(time='5D', skipna=True).mean()\n",
    "    return monthly\n",
    "\n",
    "def clean_ndvi(ds):\n",
    "    ds = ds.where('ndvi'!=0.00)\n",
    "    return ds\n",
    "\n",
    "base_dir = r'D:\\MSG\\msg_data\\netcdf_data\\processed'\n",
    "ds = xr.open_mfdataset(os.path.join(base_dir,'*.nc'))\n",
    "clouds_dir = r'D:\\MSG\\cloudmask\\processed_clouds'\n",
    "ds_cl = xr.open_mfdataset(os.path.join(clouds_dir,'time','*.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a08fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalize time in order for the two datasets to match\n",
    "ds_cl['time'] = ds_cl.indexes['time'].normalize()\n",
    "ds['time'] = ds.indexes['time'].normalize()\n",
    "\n",
    "### apply time mask\n",
    "ds = ds.where(ds.time == ds_cl.time)\n",
    "\n",
    "### apply mask and downsample to 5 days\n",
    "res_xr = ds.where(ds_cl.cloud_mask<2)\n",
    "res_xr_p = downsample(res_xr)\n",
    "\n",
    "### mask all the values equal to 0 (clouds)\n",
    "mask_clouds = clean_ndvi(ds)\n",
    "mask_clouds_p = downsample(mask_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75034db",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = '2009-12-05'\n",
    "#print('')\n",
    "ds['ndvi'].sel(time=time, method = 'nearest').plot()\n",
    "plt.title('Default NDVI image no cloud correction')\n",
    "plt.show()\n",
    "mask_clouds_p['ndvi'].sel(time=time,  method = 'nearest').plot()\n",
    "plt.title('NDVI image with max pixel value cloud correction')\n",
    "plt.show()\n",
    "res_xr_p['ndvi'].sel(time=time,  method = 'nearest').plot()\n",
    "plt.title('NDVI image with cloud mask')\n",
    "plt.show()\n",
    "ds_cl['cloud_mask'].sel(time=time,  method = 'nearest').plot()\n",
    "plt.title('Cloud mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f486fe",
   "metadata": {},
   "source": [
    "### Difference in absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mask_clouds_p['ndvi'].isel(time=0) - res_xr_p['ndvi'].isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64912559",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_clouds['ndvi'].sum(res_xr['ndvi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = mask_clouds['ndvi'] res_xr['ndvi']\n",
    "diff_p = mask_clouds_p['ndvi'] - res_xr_p['ndvi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7412eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(diff).mean('time', skipna=True).plot()\n",
    "plt.show()\n",
    "\n",
    "abs(diff_p).mean('time').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713cadd",
   "metadata": {},
   "source": [
    "### Check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0579870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xskillscore as xs\n",
    "\n",
    "# Selecting variables from the dataarray...................................\n",
    "ndvi_= res_xr['ndvi'].chunk(dict(time=-1))\n",
    "mask_= mask_clouds['ndvi'].chunk(dict(time=-1))\n",
    "\n",
    "xs.pearson_r(ndvi_, mask_, dim='time', skipna=True).plot()\n",
    "plt.show()\n",
    "\n",
    "# Selecting variables from the dataarray...................................\n",
    "ndvi_= res_xr_p['ndvi'].chunk(dict(time=-1))\n",
    "mask_= mask_clouds_p['ndvi'].chunk(dict(time=-1))\n",
    "\n",
    "xs.pearson_r(ndvi_, mask_, dim='time', skipna=True).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d348a",
   "metadata": {},
   "source": [
    "### Calculate NDVI indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(r\"C:\\Users\\Riccardo\\Desktop\\PhD docs\\Drought prediction\\formula_anomaly NDVI.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e30459",
   "metadata": {},
   "outputs": [],
   "source": [
    "###nomral anomaly\n",
    "def lta_anomaly(ds):\n",
    "    climatology = ds.groupby(\"time.month\").mean(\"time\")  ###12 months only, average per month\n",
    "    anomalies =ds.groupby(\"time.month\") - climatology  ### group data by month and subtract the average value\n",
    "    anomalies = anomalies.drop('month')\n",
    "    ds = ds.assign(ndvi_lta = anomalies['ndvi'])\n",
    "    return ds\n",
    "\n",
    "### reference anomaly with max month\n",
    "def ref_anomaly(ds):\n",
    "    climatology = ds.groupby(\"time.month\").max('time').drop('crs') ###12 months only, average per month\n",
    "    anomalies = ds.groupby(\"time.month\") - climatology ### group data by month and subtract the average value\n",
    "    #anomalies = anomalies.drop('month')\n",
    "    ds = ds.assign(ndvi_ref = anomalies['ndvi'])\n",
    "    return ds\n",
    "\n",
    "### anomaly using daily data\n",
    "\n",
    "def daily_anomaly(ds):\n",
    "    monthly = ds.resample(time='1MS').mean()  ###resample by average value per month\n",
    "    upsampled_monthly = monthly.resample(time='1D').ffill()  ### upsample filling constant values per month\n",
    "    anomalies = monthly - upsampled_monthly  ### calculating the anomaly\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767cb6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implementation of the formula\n",
    "\n",
    "def lta_anomaly_(ds):\n",
    "    monthly = ds['ndvi'].resample(time='1MS').mean('time')\n",
    "    month_12 = ds.groupby(\"time.month\").mean(\"time\")\n",
    "    daily = monthly.resample(time='1D').ffill()\n",
    "    monthly_res = daily.resample(time='1MS').first(skipna=False)\n",
    "    return (monthly - monthly_res)/ monthly_res\n",
    "\n",
    "def ref_anomaly_(ds):\n",
    "    monthly = ds['ndvi'].resample(time='1MS').mean('time')\n",
    "    daily = monthly.resample(time='1D').ffill()\n",
    "    monthly_res = daily.resample(time='1MS').first(skipna=False)\n",
    "    return (monthly - monthly_res)/ monthly_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cb34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_an = lta_anomaly(res_xr)\n",
    "ds_d_an = daily_anomaly(res_xr)\n",
    "ds_an_ref = ref_anomaly(res_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_an.sel(time=time, method = 'nearest')['ndvi_lta'].plot()\n",
    "plt.show()\n",
    "\n",
    "ds_an_ref.sel(time=time, method = 'nearest')['ndvi_ref'].plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_an_ref.mean('time')['ndvi_ref'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa0f6b",
   "metadata": {},
   "source": [
    "### Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lta = lta_anomaly_(res_xr)\n",
    "ds_lta.mean('time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36243bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ref = ref_anomaly_(res_xr)\n",
    "ds_ref.mean('time').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc1313c",
   "metadata": {},
   "source": [
    "### Importing requested cloud mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "path = r'D:\\MSG\\msg_data\\clouds data\\extracted'\n",
    "reg = r'(CFCin2009)(\\d{4})1215(.*)'\n",
    "\n",
    "r = re.compile(reg)\n",
    "for root, dirs, files in os.walk(path):\n",
    "    l = [os.path.join(root,x) for x in files if r.match(x)]\n",
    "    \n",
    "new_list = [i.rsplit('\\\\')[-1]for i in l]\n",
    "\n",
    "#List all files in path\n",
    "for filename in os.listdir(path):\n",
    "  \n",
    "    #If file is not present in list\n",
    "    if filename not in new_list:\n",
    "        #Get full path of file and remove it\n",
    "        os.remove(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263cba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_cl = xr.open_dataset(l[0])\n",
    "xr_cl['CMa'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis2_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1acf0cf36a713a20e6f2f6b404d47f8424c3d1e89d00c3598e855a17bfb20dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
